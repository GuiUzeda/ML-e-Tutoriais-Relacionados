{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFRecods: datasets dentro do Tensorflow",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GuiUzeda/ML-e-Tutoriais-Relacionados/blob/master/TFRecods_datasets_dentro_do_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "IH18u0ARheSv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TFRecods: *datasets* dentro do *Tensorflow*\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "eQCDxFcrxPz2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## 1 Introdução:\n",
        "\n",
        "*TFRecords* é um tipo de dados binário criado especiamente para ser utilizado em pipelines de dados no Tensorflow. Principalmente quando se está trabalhando com grandes séries de dados, usar um formato de dados binário traz uma série de melhorias de performance no treinamento do modelo. Esse modelo descomplica o gerenciamento de *datasets* e pode diminuir os tempos de treinamento.\n",
        "\n",
        "Os dados utilizados aqui podem ser encontrados em: https://pjreddie.com/projects/cifar-10-dataset-mirror/.\n",
        "Para os testes em TPU o [Google Colab](https://colab.research.google.com) pode ser utilizado sem perdas.\n",
        "\n",
        "----\n",
        "\\*Esse notenook tem dependência entre as células, ou seja, células mais ao final fazem uso de classes, funções, variáveis e dados criadas nas células anterios"
      ]
    },
    {
      "metadata": {
        "id": "Z6nebYgexCxp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2 Objetivo\n",
        "\n",
        "Esse *Notebook* tem por objetivo demonstrar a tulização de *TFRecords* para salvar, ler e manipular datasets. Adicionalmente, como conteúdo complementar, este material faz uma breve introduçao sobre como incorporar *data augmentation* em um *dataset* do *Tensorflow*"
      ]
    },
    {
      "metadata": {
        "id": "CIr0jYgOme4Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3 TFRecords\n",
        "\n",
        "[*TFRecords*](https://www.tensorflow.org/api_guides/python/python_io) é um tipo de dados binário criado especiamente para ser utilizado em *pipelines* de dados no *Tensorflow*. Principalmente quando se está trabalhando com grandes séries de dados, usar um formato de dados binário traz uma série de melhorias de performance no treinamento do modelo. Isso por que dados binarizados ocupam menos espaço e demoram menos tempo para serem lidos do disco (especialmente dos discos rígidos). Além disso, a otimização do modelo *TFRecodrs* no *Tensorflow* permite trabalhar com dados de forma mais eficiente e com uma boa integração às APIs de alto nível como os *Estimators*.\n",
        "\n",
        "Ao invés de carregar os dados para a memória Python em formato Pandas ou Numpy para depois serem transformados em Tensores dentro do Grafo, o *TFRecord* permite que os dados sejam carregados para dentro da seção do *Tensorflow* sem intermediário. Isso é importante especialmente quando se tem uma série de dados muito grande ou dividia em mais de um arquivo, uma vez que apenas as partes necessárias para cada etapa de treinamento (*batches*) são carregadas do disco e processadas. Entretanto, a grande inconveniência desse modelo é que é necessário transformar todos os dados antes de qualquer processamento."
      ]
    },
    {
      "metadata": {
        "id": "x00o0PeLuAbT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.1 Estrutura do TFRecord\n",
        "\n",
        "*TFRecord*  armazena os dados em *strings* binárias, isso significa que é preciso especificar qual a estrutura de dados. Para isso, existem dois componentes no *Tensorflow*: [tf.train.Example](https://www.tensorflow.org/api_docs/python/tf/train/Example) e [tf.train.SequenceExample](https://www.tensorflow.org/api_docs/python/tf/train/SequenceExample), sendo que a diferença entre eles é que o primeiro é uma lista de propriedades de cada exemplo e o segundo é uma lista de listas de propriedades de cada exemplo. Cada um dos dados de exemplos precisam ser armazedos em um desses dois formatos, serializados e gravados no disco utilizado [tf.python_io.TFRecordWriter ](https://www.tensorflow.org/api_docs/python/tf/python_io/TFRecordWriter). Vale lembrar que `tf.train.Example` não é uma classe, mas um protocolo de *buffer*. Um protocolo de *Buffer* é um metodo desenvolvido pelo Google para serializar estruturas de dados de forma eficiente.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "wXGB1FVEyxHx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.2 Convertendo os dados em TFRecord\n",
        "\n",
        "Nesta seção os dados são convertidos em TFRecord utilizando o método `tf.train.Example`. Os dados que utilizaremos são images da base de dados **CIFAR-10**. Basicamente são imagens quadrades (32X32) com 10 classes diferentes e mais informações sobre o dataset podem ser encontradas [aqui](https://www.cs.toronto.edu/~kriz/cifar.html). As imagens estão normalizadas e são representadas como tipo *float*. Primeiramente é necessário fazer o download das images e descompactar os arquivos:"
      ]
    },
    {
      "metadata": {
        "id": "0w6sYDSfyu3m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Download dos arquivos\n",
        "!wget http://pjreddie.com/media/files/cifar.tgz\n",
        "  \n",
        "# Descompactar os arquivos na pasta Cifar\n",
        "!tar xzf cifar.tgz\n",
        "        \n",
        "# Criar um diretório para os novos TFRecords\n",
        "!mkdir cifar_tfrecords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RB4pXv7Ej8X-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Os dados que foram descompactados estão organizados e divididos em duas pastas: *train* e *test*. Há também um arquivo com 10 classes que pode ser considerado como um \"vocabulário\" de classificão. É possível ver as classes com o comando:"
      ]
    },
    {
      "metadata": {
        "id": "1VfvibpV0nnH",
        "colab_type": "code",
        "outputId": "0a0c5857-c1bd-4c80-81bf-d0ecf613844d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "cell_type": "code",
      "source": [
        "!cat cifar/labels.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "airplane\n",
            "automobile\n",
            "bird\n",
            "cat\n",
            "deer\n",
            "dog\n",
            "frog\n",
            "horse\n",
            "ship\n",
            "truck\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4aqgGaG_qXkp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Antes de começar a mexer com os dados é necessário importar as bibliotecas necessárias"
      ]
    },
    {
      "metadata": {
        "id": "0U4jK2zxvY6o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xpPT6y2Qv8_m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Os dados do Cifar-10 adiquiridos anteriormente já estão bem divididos entre treino e teste. Se este não fosse o caso aqui seria uma boa hora para dividí-los e garantir que os *sets* de treino e teste não se misturem. É possível, também, dividir os dados dentro da classe *Dataset* do *Tensorflow* no momento da leitura do *dataset*.\n",
        "\n",
        "O código a baixo está definindo qual o caminho absoluto da pasta dos dados e armazenando na variável `cifar_path`. Apesar de ser possível usar apenas caminhos relativos para para referenciar o local das imagens é mais aconselhável fazê-lo com os caminhos absolutos. \n",
        "\n",
        "O *dataset* que está sendo trabalhado aqui é composto por imagens de 32X32 píxeles armazenadas em duas pastas: *train* e *test*. O nome de cada imagem é composto por um *id* e pela classe de classificação no padrão: `id_classe.png`. Assim, uma lista das imagens de treino e teste é armazenada em um dicionário para facilitar a consulta posterior.\n",
        "\n",
        "Como já mencionado, o arquivo `labels.txt` estão registradas as 10 classes possíveis para as imagens. Nota-se que, para aplicação de redes neurais, não é possível utilizar as classes pelos seus nomes, por isso uma codificação será feita. Para facilitar tal processo, cria-se um `tuple` com os nomes das classes que servirá de referência para essa codificação.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "IhfGHhf5wUgP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define o caminho absoluto para a pasta cifar\n",
        "cifar_path = os.path.join(os.getcwd(), \"cifar\")\n",
        "\n",
        "# Lê a lista de imagens e coloca em um dicinário\n",
        "data_dict = { \n",
        "    \"train\": os.listdir(os.path.join(cifar_path, \"train\")),\n",
        "    \"test\" : os.listdir(os.path.join(cifar_path, \"test\"))\n",
        "}\n",
        "\n",
        "# Lê os arquivos com as classes e coloca um um taple chamado labels\n",
        "with open(os.path.join(cifar_path, \"labels.txt\"), \"r\") as file:\n",
        "\n",
        "  \tlabels_tuple = tuple( file.read().splitlines() )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lb6YfdZTyyT1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Como já dito anteriormente, o *TFRecord* armazena os dados como um sequencia binária, ou seja, é preciso determinar qual a estrutura dos dados antes de escrevê-los no arquivo para que possam ser recuperados da forma correta. Nesse caso vamos usar o protocolo de buffer  `tf.train.Example` (lembrando que  ` tf.train.Example` não é uma classe comum do python) e `tf.python_io.TFRecordWriter`para escrever os dados no disco. \n",
        "\n",
        "Neste caso temos apenas duas *features*: a image e a classe. Na realidade a classe não é uma *feature*, mas para facilitar a leitura dos dados e garantir que os pares de dados sem lidos de forma correta vamos encapsular as classes dentro de uma *feature*. \n",
        "\n",
        "Um ` tf.train.Example` é composto por várias *features* definidas por `tf.train.Features`, que por sua vez é um dicionário de mais de uma `tf.train.Feature`. Por fim, `tf.train.Feature` é composto por `tf.train.BytesList`, `tf.train.FloatList` ou `tf.train.Int64List`, que determinam qual o tipo dos dados dentro de cada *feature*. Por exemplo:\n",
        "\n",
        "```\n",
        "image_byteslist = tf.train.BytesList(value=[iamge_bytes])\n",
        "label_intlist = tf.train.Int64List(value=[int_label])\n",
        "\n",
        "image_feture = tf.train.Feature(bytes_list=image_byteslist)\n",
        "label_feature = tf.train.Feature(int64_list=label_intlist)\n",
        "\n",
        "dict_feature = {\n",
        "      \"img\" : image_feture,\n",
        "      \"label\" : label_feature\n",
        "      }\n",
        "features = tf.train.Features(feature = dict_feature)\n",
        "example = tf.train.Example(features = features)\n",
        "```\n",
        "\n",
        "No caso das imagens, serão lidos e salvos no *TFRecord* os bytes das imagens. Já as classes serão codificadas conforme o tuple `label` seguindo a seguinte regra:\n",
        "\n",
        ">Nome da Classe | Código\n",
        ">--- | --- \n",
        ">airplane | 0\n",
        ">automobile| 1\n",
        ">bird| 2\n",
        ">cat| 3\n",
        ">deer| 4\n",
        ">dog| 5\n",
        ">frog| 6\n",
        ">horse|7\n",
        ">ship| 8\n",
        ">truck| 9\n"
      ]
    },
    {
      "metadata": {
        "id": "VluKkaC2cw2V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# As classes vão ser posteriormente codificadas em um array por isso devem se manter\n",
        "# na mesma posição de o arquivo labels.txt\n",
        "\n",
        "# Loop nas listas do data_dict\n",
        "for key, values in data_dict.items():\n",
        "  \n",
        "  #Cria um writer capaz de escrever os arquivos .tfrecord\n",
        "  with tf.python_io.TFRecordWriter(os.path.join('cifar_tfrecords',key+'.tfrecord' )) as writer:\n",
        "    \n",
        "    # Para cada nome de arquivo é preciso ler os bytes da imagem e\n",
        "    # codificar a classe com base no nome da imagem \n",
        "    \n",
        "    for img_name in values:\n",
        "      # Separa o nome da classe do nome da imagem\n",
        "      img_label_name = img_name[:-4].split(\"_\")[-1]\n",
        "      # Pega o código da classe confrome o index do tuple labels\n",
        "      img_label = labels_tuple.index(img_label_name)\n",
        "\n",
        "      # Cria um protocolo Feature com o valor inteiro da classe\n",
        "      label_feature = tf.train.Feature(int64_list=tf.train.Int64List(value=[img_label]))\n",
        "      \n",
        "      # Lê os bytes da imagem\n",
        "      with open(os.path.join(cifar_path,key,img_name), 'rb') as file:        \n",
        "        img_feature = tf.train.Feature(bytes_list=tf.train.BytesList(value=[file.read()]))\n",
        "      \n",
        "      # Cria um exemplo com as features img e label e salva no .tfrecord\n",
        "      feature = {'label': label_feature,\n",
        "                 'img': img_feature}\n",
        "      example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "      writer.write(example.SerializeToString())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g0E8ZybnwAVy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.3 Lendo TFRecord\n",
        "\n",
        "Para ler os arquivos os seguintes passos são necessários:\n",
        "\n",
        "\n",
        "\n",
        "1.   **Criar uma lista com os nomes de arquivos:** Podem ser lidos mais de um arquivo por vez, mas no caso aqui utilizado a lista vai apenas conter os dados de treino `[\"cifar_tfrecords/train.tfrecord\"]`;\n",
        "2.   **Criar um *Dataset* com os arquivos *TFRecord*:** Para isso, utiliza-se `tf.data.TFRecordDataset`\n",
        "3. **Criar uma função para decodificar as imagens e as classes:** Essa função decodifica o um exemplo restaurando as features\n",
        "4. **Decodificar cada exemplo do *dataset*:** Usadndo `Dataset.map` aplica-se a função criada no item anterior para cada um dos dados do *dataset*\n",
        "5. **Construir um *Iterator*:** com `make_one_shot_iterator()` podemos criar um *Iterator* que vai ser responsável para pegar o próximo item do *dataset* e colocar em um tensor\n",
        "6. **Abrir um seção do *Tensorflow*:** Dentro da seção podemos avaliar os tensores os exemplos do *dataset*\n",
        "7. **Ler um exemplo do *dataset*:** Usando `get_next()` criamos tensores com os dados de um exemplo\n",
        "8. **Avaliar os tensores:** Com `sess.run()` avaliasse os tensores para plotar a imagem e mostrar a classe\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "kERldtKGOE5-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Aqui uma das vantagens do *TFRecords* fica clara. A leitura dos dados ocorre de forma transprarente, sem a necessidade de carregar as imagens para a memória python em formato numpy. Ao contrário, os dados são alocados diretamente em tensores com a função `parser`\n",
        "\n",
        "A função aqui denominada `parser` é responsável por decodificar um exemplo do arquivo *TFRecord* da forma correta. Um dicionário vai guiar cada uma das features e designar um forma (*shape*), um tipo e um padrão para os casos de ausência de dados. Isso pode ser feito utilizando `tf.FixedLenFeature` ou  `tf.VarLenFeature`. Vale lembrar que as chaves do dicionário devem ter o mesmo nome dos das *featuatures* que salvamos na seção anterior. De froma simples, `tf.parse_single_example` pode ser utilizado agora para ler o exemplo serealizado. Adicionalemente deve-se usar `tf.image.decode_jpeg` para decodificar o texto de bytes em um tensor numérico e usar `set_shape` para definir a forma da imagem. Quanto as classes, apenas uma `tf.cast` é necessário para deira no formato correto"
      ]
    },
    {
      "metadata": {
        "id": "ttVPmx_v_GMZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def parser(serialized_example):\n",
        "  \"\"\" \n",
        "  Função para decodificar um exemplo do TFRecord de acordo com \n",
        "  o tipo de cada uma das features\n",
        "  \"\"\"\n",
        "  \n",
        "  # Cria um dict que dita o shape, type e dafault de cada feature\n",
        "  features_dict = {\n",
        "          'img': tf.FixedLenFeature([], tf.string),\n",
        "          'label': tf.FixedLenFeature([], tf.int64),\n",
        "      }\n",
        "  \n",
        "  # Deserealiza o exemplo\n",
        "  features = tf.parse_single_example(\n",
        "      serialized_example,\n",
        "      features=features_dict)\n",
        "  \n",
        "  # Decodifica a imagem de bytes para int8 e determina o tamanho para 32X32X3\n",
        "  image  = tf.image.decode_jpeg(features['img'], channels=3)\n",
        "  image.set_shape([32 , 32,3])\n",
        "\n",
        "  # Assegura que as labels estão no tipo int32\n",
        "  label = tf.cast(features['label'], tf.int32)\n",
        "  \n",
        "  return image, label\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BnFw--BlOIxq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A função `map` funciona de forma muito parecida da função `map` do python, a diferença é que aqui ao invés de ser processada no *runtime* python o processamento acontece dentro da seção do *Tensorflow*. \n",
        "\n",
        "O *Iterator* nada mais é do que uma fila onde um ou mais exemplos são tirados por vez. É possível definir *iterators* (re)inicializáveis e também salvar o estado de um *iterator*. Para maiores informações verificar a [documentação](https://www.tensorflow.org/api_guides/python/reading_data)\n",
        "\n",
        "A saída da célula a baixo é um exmplo de imagem com sua respectiva classe. Aqui foi usada a *tuple* criada anteriormente para decodificar também a classe para texto"
      ]
    },
    {
      "metadata": {
        "id": "FYkjPB20AASR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Lista de arquivos TFRecord a serem lidos, podem ser passados N arquivos\n",
        "train_filenames = [\"cifar_tfrecords/train.tfrecord\"]\n",
        "\n",
        "# Cria o dataset a partir do TFRecord e mapeia os exemplos com a função parser\n",
        "dataset = tf.data.TFRecordDataset(train_filenames)\n",
        "dataset = dataset.map(parser, num_parallel_calls=1)\n",
        "\n",
        "# Cria um Iterator\n",
        "iterator = dataset.make_one_shot_iterator()\n",
        "with tf.Session() as sess:\n",
        "  features, labels = iterator.get_next()\n",
        "  image, label = sess.run([features, labels])\n",
        "  plt.imshow(image)\n",
        "  plt.title(labels_tuple[label])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WuYRCkcNnCS8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4 Manipulando *datasets* e *data augmentation*\n",
        "\n",
        "Uma vez que o *dataset* está criado dentro do grafo do *Tensorflow* é possível aplicar algumas manipulações como embaralhar, dividir e agrupar *batches*. A classe [`tf.data.Dataset`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) tem algumas funções muito úteis para manipular dados. Uma lista completa de funções pode ser encontrada na documentação, mas as funções mais usadas são as seguintes:\n",
        "\n",
        ">Função | Descrição | Exemplo\n",
        ">--- | --- | ---\n",
        ">apply | Aplica uma transformação no *dataset* | `apply(func_transfor)`\n",
        ">batch | Combina elementos consecutivos do *dataset* em um *batch* | `batch(tamanho_batch, drop_remainder=False)`\n",
        ">cache | Coloca os elementos de um *dataset* em *cache* | `cache(filename='arquivo_cache')`\n",
        ">concatenate | Cria um novo *dataset* concatenando dois *datasets* | `concatenate(dataset)`\n",
        ">flat_map | Mapeia uma função em todo o *dataset* e \"achata\" o resultado | `flat_map(map_func)`\n",
        ">map | Mapeia uma função em todo o *dataset* | `map(map_func,num_parallel_calls=None)`\n",
        ">reduce | Agrega o *dataset* em um único elemento a partir de um função | `reduce(initial_state,reduce_func)`\n",
        ">repeat | Repete o *dataset* n vezes |`repeat(count=None)`\n",
        ">shuffle | Embaralha o *dataset* aleatoreamente | `shuffle(tamanho_buffer,seed=None,reshuffle_each_iteration=None)`\n",
        ">skip| Cria um *dataset* que deixa de fora n elementos do *dataset* original | `skip(count)`\n",
        "> take | Cria um *dataset* com no máximo n elementos do *dataset* original | `take(count)`\n",
        "\n",
        ">**Importante:** para efeitos de performance é recomendável evitar shuffle após batch\n",
        "\n",
        "No caso de imagens é possível ainda é possível fazer *data augmentation* ao ler as images para obter um grau de generalização melhor do modelo. Tal procedimento pode ser feito de forma muito eficiente dentro do *Tensorflow* utilizando o módulo [`tf.image`](https://www.tensorflow.org/api_docs/python/tf/image) ao invés de se pré-processar ou processar os exemplos durante o treino. Tal abordagem poupa de forma significativa espaço em disco e memória e possibilita maior velocidade de treino, uma vez que o *Tensorflow* apenas carrega para a memória os dados necessários para cada *step*.\n",
        "\n",
        "A baixo um exemplo de como algumas dessas funções entrariam no *pipe line* criado acima. Nota-se que a manipulação de imagens é feita diretamente dentro da função `parser` que, por sua vez, é mapeada para cada elemento do *dataset*. A saída das células a baixo deve mudar cada vez que é executada devido à função `shuffle`.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "_L4GCEnHEQwE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def data_augmentation(iamge):\n",
        "  \"\"\"\n",
        "  Uma função ilustrativa de data augmentation apenas para mostrar como aplicar\n",
        "  esse tipo de procedimento em um dataset do Tensorflow\n",
        "  \"\"\"\n",
        "  \n",
        "  image = tf.image.random_brightness(image,.2)\n",
        "  image = tf.image.random_flip_left_right(image)\n",
        "  random_crop_factor = tf.random.uniform([1],0,.2)\n",
        "  image = tf.image.random_crop(image, [25,25,3])\n",
        "  return image\n",
        "  \n",
        "  \n",
        "def parser(serialized_example):\n",
        "  \"\"\" \n",
        "  Função para decodificar um exemplo do TFRecord de acordo com \n",
        "  o tipo de cada uma das features com data augmentation para as imagens\n",
        "  \"\"\"\n",
        "  \n",
        "  # Cria um dict que dita o shape, type e dafault de cada feature\n",
        "  features_dict = {\n",
        "          'img': tf.FixedLenFeature([], tf.string),\n",
        "          'label': tf.FixedLenFeature([], tf.int64),\n",
        "      }\n",
        "  \n",
        "  # Deserealiza o exemplo\n",
        "  features = tf.parse_single_example(\n",
        "      serialized_example,\n",
        "      features=features_dict)\n",
        "  \n",
        "  # Decodifica a imagem de bytes para int8 e determina o tamanho para 32X32X3\n",
        "  image  = tf.image.decode_jpeg(features['img'], channels=3)\n",
        "  image.set_shape([32 , 32,3])\n",
        "  \n",
        "  image = data_augmentation(image)\n",
        "\n",
        "  # Assegura que as labels estão no tipo int32\n",
        "  label = tf.cast(features['label'], tf.int32)\n",
        "  \n",
        "  return image, label\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mMygU8heEhmK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Lista de arquivos TFRecord a serem lidos, podem ser passados N arquivos\n",
        "train_filenames = [\"cifar_tfrecords/train.tfrecord\"]\n",
        "# Define o tamanho do batch\n",
        "batch_size = 5\n",
        "# Cria o dataset a partir do TFRecord\n",
        "dataset = tf.data.TFRecordDataset(train_filenames)\n",
        "\n",
        "# Embaralha o dataset com um buffer 2x o tamanho do batch\n",
        "dataset = dataset.shuffle(batch_size*2)\n",
        "\n",
        "# Mapeia os exemplos com a função parser\n",
        "dataset = dataset.map(parser, num_parallel_calls=1)\n",
        "\n",
        "# Retepe o dataset 5 vezes (apenas para efeito ilustrativo)\n",
        "dataset = dataset.repeat(5) \n",
        "\n",
        "# Cria os batches\n",
        "dataset = dataset.batch(batch_size)\n",
        "\n",
        "# Cria o gráfico para plotar as imagens\n",
        "n_cols = min(10, batch_size)\n",
        "n_rows = int(batch_size/n_cols) + min(1, batch_size%n_cols)\n",
        "fig, ax = plt.subplots(n_rows, n_cols)\n",
        "fig.tight_layout()\n",
        "fig.dpi=120\n",
        "ax = ax.ravel()\n",
        "\n",
        "# Cria um Iterator\n",
        "iterator = dataset.make_one_shot_iterator()\n",
        "\n",
        "# Inicia uma seção do Tensorflow\n",
        "with tf.Session() as sess:\n",
        "  \n",
        "  # Carrega o próximo batch de acordo com o iterator\n",
        "  features, labels = iterator.get_next()\n",
        "  # Avalia efetivamente as imagens e labels\n",
        "  images, labels = sess.run([features, labels])\n",
        "  \n",
        "  # Plota as imagens \n",
        "  for n,il in enumerate(zip(images, labels)):\n",
        "    image=il[0]\n",
        "    label=il[1]\n",
        "    ax[n].set_axis_off()\n",
        "    ax[n].imshow(image)\n",
        "    ax[n].set_title(labels_tuple[label])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x8Rtk-QdxwQL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 5 Conclusão\n",
        "\n",
        "*TfRecords* é um formato de arquivo que pode auxiliar de forma significativa o treino de uma rede neural, pois os dados são lidos de forma gradual e conforme a necessidade. Entretanto o lado negativo é a necessidade de conversão dos arquivos originais que, apesar de ser simples e ocorrer apenas uma vez, pode demorar algum tempo. Juntamente com *TFRecord* utilizar *datasets* dentro do *Tensorflow* facilita a manipulação de dados de forma mais automatizada e intuitiva. Além disso, torna-se mais facil de trabalhar com *data augmentation* durante o treino, sem a necessidade de pré processar todo o *dataset*.\n",
        "\n",
        "Esse material não extingue o assunto, mas ao contrário, contém uma introdução do conteúdo abordado. Vale lembrar que esse é um conteúdo aberto e comunitário, contribuições, corressões e sujestões são sempre bem-vindas!"
      ]
    }
  ]
}